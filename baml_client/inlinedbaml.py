# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "geocode.baml": "// BAML functions for precision geocoding\n// Used by abxgeo to resolve vague locations to precise addresses\n\nclass LocationClassification {\n  category string @description(\"One of: 'skip', 'simple', 'research'\")\n  reason string @description(\"Why this category was chosen\")\n  simple_address string? @description(\"If category is 'simple', provide the well-known address (e.g., '1 Infinite Loop, Cupertino, CA')\")\n  estimated_precision string? @description(\"If category is 'simple', estimated precision: 'address', 'city', etc.\")\n}\n\nclass AddressResolution {\n  address string @description(\"Full street address if found, otherwise most specific location found\")\n  lat float? @description(\"Latitude coordinate\")\n  lon float? @description(\"Longitude coordinate\")\n  precision string @description(\"One of: 'address', 'street', 'intersection', 'city', 'region', 'country'\")\n  source_url string @description(\"URL where this information was found\")\n  source_snippet string @description(\"Exact text snippet from source that contains the address/location info\")\n  confidence float @description(\"Confidence score 0.0-1.0 based on source reliability and specificity\")\n  is_residence bool @description(\"True if this is a private residence\")\n  corroboration string[] @description(\"List of corroborating evidence from other sources\")\n  concerns string[] @description(\"Any red flags or uncertainty factors\")\n  reasoning string @description(\"Brief explanation of how address was found and confidence score\")\n}\n\nfunction FindPreciseAddress(\n  place_name: string,\n  place_type: string?,\n  note: string?,\n  story_title: string,\n  story_summary: string,\n  original_lat: float?,\n  original_lon: float?\n) -> AddressResolution {\n  client GeocodeModel\n  prompt #\"\n    You are a geocoding expert tasked with finding the precise street address for a location.\n\n    IMPORTANT: You have access to web search. USE IT to find authoritative sources with precise addresses.\n    Search multiple sources if needed to corroborate information.\n\n    LOCATION TO FIND:\n    Place Name: {{ place_name }}\n    Place Type: {{ place_type or \"unknown\" }}\n    Context Note: {{ note or \"none\" }}\n    Original Coordinates: {% if original_lat and original_lon %}{{ original_lat }}, {{ original_lon }}{% else %}none{% endif %}\n\n    STORY CONTEXT:\n    Title: {{ story_title }}\n    Summary: {{ story_summary }}\n\n    TASK:\n    Use web search to find the precise street address and coordinates for this location.\n\n    IMPORTANT - HANDLING VAGUE LOCATIONS:\n    - If the location is too vague (e.g., \"United States\", \"California\", \"Asia\") WITHOUT sufficient context to identify a specific building/address, DO NOT try to force a street address\n    - For vague country/region references, return just the country/region name with low confidence (0.1-0.3)\n    - Set precision to \"country\" or \"region\" accordingly\n    - In the \"concerns\" field, note: \"Location too vague - insufficient context for specific address\"\n    - ONLY search for specific addresses if there are clear clues (company name, factory, headquarters, landmark, event, etc.)\n\n    SEARCH STRATEGY (only if location is specific enough):\n    1. For factories: search \"company name + factory + city + address\"\n    2. For headquarters: search \"company name + headquarters + city + year + address\"\n    3. For residences: be respectful of privacy, focus on historical/public records\n    4. For landmarks: search \"landmark name + city + address\"\n    5. Include time period context if mentioned (e.g., \"1980s\", \"1984\")\n    6. For vague references: accept the vagueness, don't force a search\n\n    EXTRACTION RULES:\n    1. Look for complete street addresses (number, street, city, state, zip)\n    2. If no street address, look for coordinates (lat/lon)\n    3. If no coordinates, extract the most specific location mentioned\n    4. Determine precision level: address > street > intersection > city > region > country\n    5. Extract exact source URL and text snippet containing the address (use \"N/A\" if too vague to search)\n    6. Assign confidence based on:\n       - Source reliability: .gov/.edu (0.9-1.0), Wikipedia (0.7-0.8), news (0.6-0.8), forums (0.3-0.5)\n       - Specificity: exact address (1.0), intersection (0.7), city only (0.3), region (0.1-0.2), country (0.1)\n       - Corroboration: multiple sources increase confidence (+0.1 if 2+ sources agree)\n    7. Flag if location is a private residence (is_residence = true)\n    8. Cross-check coordinates if original coords were provided (should be nearby, within ~1km)\n    9. List corroborating evidence and any concerns\n\n    EXAMPLES:\n    ✓ \"702 Bandley Drive, Fountain, Colorado 80817\" → precision: address, confidence: 0.95\n    ✓ \"Corner of Bandley Dr and Main St\" → precision: intersection, confidence: 0.7\n    ✓ \"Somewhere in Fountain, Colorado\" → precision: city, confidence: 0.3\n    ✓ \"United States\" (vague context) → precision: country, confidence: 0.1, concerns: [\"Location too vague - insufficient context\"]\n    ✗ Don't force \"United States\" → \"1600 Pennsylvania Ave\" without specific context mentioning White House\n\n    Return a JSON object with the AddressResolution structure:\n    {\n      \"address\": \"full street address or country/region name if too vague\",\n      \"lat\": 37.123 or null,\n      \"lon\": -122.456 or null,\n      \"precision\": \"address|street|intersection|city|region|country\",\n      \"source_url\": \"http://... or 'N/A' if too vague to search\",\n      \"source_snippet\": \"exact text from source or 'N/A' if too vague\",\n      \"confidence\": 0.1 to 1.0,\n      \"is_residence\": false,\n      \"corroboration\": [\"evidence 1\", \"evidence 2\"] or [] if too vague,\n      \"concerns\": [\"Location too vague - insufficient context\"] or other concerns,\n      \"reasoning\": \"explanation of how address was found and confidence score, or why location is too vague\"\n    }\n  \"#\n}\n\n\nfunction ClassifyLocation(\n  place_name: string,\n  place_type: string?,\n  note: string?,\n  story_title: string,\n  story_summary: string\n) -> LocationClassification {\n  client GPT5Mini\n  prompt #\"\n    You are a location classifier for a geocoding system. Categorize this location into one of three tiers to optimize processing.\n\n    LOCATION:\n    Place Name: {{ place_name }}\n    Place Type: {{ place_type or \"unknown\" }}\n    Context Note: {{ note or \"none\" }}\n\n    STORY CONTEXT:\n    Title: {{ story_title }}\n    Summary: {{ story_summary }}\n\n    CATEGORIZATION RULES:\n\n    1. SKIP - Vague country/region with NO specific clues:\n       - Generic country references: \"China\", \"Japan\", \"Taiwan\" WITHOUT company name or city\n       - Notes like \"supplier region\", \"generic reference\", \"country not specified\"\n       - Large regions: \"Asia\", \"Europe\", \"Middle East\" WITHOUT company/factory context\n       → Return category: \"skip\", reason: why it's too vague\n\n    2. SIMPLE - Well-known landmarks, capitals, or company headquarters:\n       - Famous places: \"Beijing\" (capital), \"Tokyo\" (capital), \"White House\"\n       - Company HQs with context: \"Cupertino, California\" + Apple → \"1 Infinite Loop, Cupertino, CA 95014\"\n       - Major landmarks: \"Eiffel Tower\", \"Golden Gate Bridge\"\n       → Return category: \"simple\", simple_address: the well-known address, estimated_precision: address/city\n\n    3. RESEARCH - Specific or inferable locations needing web search:\n       - Explicit location: \"Fountain, Colorado factory\", \"Fremont plant\", \"Changsha facility\"\n       - Company-inferred location: \"Quanta factory\" (Quanta is Taiwanese → search Taiwan factories)\n       - Context clues: Story mentions country/region/year that narrows down location\n       - Historical sites requiring research\n       - IMPORTANT: If place_name contains a company name (Foxconn, Quanta, Pegatron, etc.):\n         * Check story context for country/region mentions\n         * Use company's known primary locations (e.g., Quanta = Taiwan, Foxconn = China/Taiwan)\n         * If ANY context clue exists (year, country in story, company origin) → RESEARCH\n       → Return category: \"research\", reason: what needs to be researched and what clues exist\n\n    EXAMPLES:\n\n    ✓ \"China\" + type: country + note: \"Supplier region for multi-touch\" + story: generic supply chain\n      → skip (vague country, no specific facility, no company name)\n\n    ✓ \"Cupertino, California\" + story about Apple + note: \"Apple's home base\"\n      → simple (1 Infinite Loop, Cupertino, CA 95014)\n\n    ✓ \"Beijing\" + type: city + note: \"Policy document location\"\n      → simple (Beijing, China - capital city)\n\n    ✓ \"Fountain, Colorado\" + type: factory + note: \"Apple Macintosh factory, 340,000 sq ft\"\n      → research (specific factory needs address lookup)\n\n    ✓ \"Japan\" + type: country + note: \"Canon manufactured LaserWriter\"\n      → skip (country-level, no specific Canon factory mentioned, no year/city context)\n\n    ✓ \"Quanta factory\" + type: factory + note: \"(location not specified)\" + story: mentions Taiwan supplier, 2010\n      → research (Quanta is Taiwanese company, story has Taiwan context + year → search \"Quanta factory Taiwan 2010\")\n\n    ✓ \"Foxconn facility\" + type: factory + note: \"iPhone production\" + story: supply chain in China\n      → research (Foxconn has China/Taiwan factories, story context mentions China → search specific facility)\n\n    ✓ \"Tokyo, Japan\" + note: \"dinner with Sony executives at exclusive restaurant\"\n      → simple (Tokyo, Japan - major city with known coordinates)\n\n    Return JSON with: category, reason, and optionally simple_address + estimated_precision.\n  \"#\n}\n\n\n// GeocodeModel client for geocoding (uses gpt-5 with web search)\nclient<llm> GeocodeModel {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    reasoning {\n      effort \"medium\"\n    }\n    tools [\n      {\n        type \"web_search_preview\"\n      }\n    ]\n  }\n}\n\n// GPT5Mini client for fast classification (cheap, no web search)\nclient<llm> GPT5Mini {\n  provider openai-responses\n  options {\n    model \"gpt-5-mini\"\n  }\n}\n\n\n// ============================================================================\n// CLUSTER SUMMARIZATION\n// ============================================================================\n// Used by abxgeo cluster command to generate narrative summaries for clusters\n\nclass ClusterSummary {\n  summary string @description(\"2-3 sentence narrative summary highlighting the story arc at this location\")\n  key_themes string[] @description(\"3-5 key themes across stories (e.g., 'manufacturing crises', 'retail expansion')\")\n  date_range string @description(\"Date range like '1984-1997' or 'mid-1990s' or '2010s'\")\n  story_count int @description(\"Number of stories in this cluster\")\n}\n\nfunction SummarizeCluster(\n  stories: string[],\n  location_name: string,\n  zoom_level: int\n) -> ClusterSummary {\n  client GPT5Mini\n  prompt #\"\n    You are creating a compelling narrative summary for a geographic cluster of stories.\n\n    LOCATION: {{ location_name }}\n    ZOOM LEVEL: {{ zoom_level }}\n    STORY COUNT: {{ stories | length }}\n\n    STORIES:\n    {% for story in stories %}\n    {{ loop.index }}. {{ story }}\n    {% endfor %}\n\n    TASK:\n    Analyze these {{ stories | length }} stories and create a narrative summary that:\n    1. Highlights the story arc and key events at this location\n    2. Emphasizes what makes this location significant\n    3. Captures the time period and evolution of events\n    4. Is engaging and informative (2-3 sentences)\n\n    EXAMPLES OF GOOD SUMMARIES:\n\n    Location: Cupertino, California\n    Stories: 15 stories about iMac manufacturing, 1998-1999\n    ✓ GOOD: \"In 1998-1999, Apple's Cupertino campus became the epicenter of the iMac crisis. Engineers battled 'unmanufacturable' designs, faced explosive tooling reviews from Steve Jobs, and orchestrated a dramatic turnaround that shipped the translucent computer on time. The saga included contractor failures, 24/7 'Man on Mir' embeds at suppliers, and Jony Ive's private apologies.\"\n\n    Location: Shenzhen, China\n    Stories: 8 stories about Foxconn iPhone production, 2010-2015\n    ✓ GOOD: \"Foxconn's Shenzhen facilities transformed from Mac enclosure supplier in the late 1990s to the heart of iPhone mass production in the 2010s. The campus housed hundreds of thousands of workers, faced labor scrutiny from Apple audits, and pioneered high-precision manufacturing techniques that defined modern consumer electronics.\"\n\n    EXTRACT KEY THEMES:\n    Identify 3-5 recurring themes across the stories. Examples:\n    - \"manufacturing crises\"\n    - \"retail expansion\"\n    - \"supply chain optimization\"\n    - \"labor conditions\"\n    - \"design conflicts\"\n    - \"regulatory challenges\"\n    - \"executive leadership\"\n\n    DETERMINE DATE RANGE:\n    Extract the date range from the stories. Format examples:\n    - \"1984-1997\" (specific years)\n    - \"mid-1990s\" (decade reference)\n    - \"2010s\" (decade)\n    - \"1976\" (single year if all stories from same year)\n\n    Return JSON with ClusterSummary structure:\n    {\n      \"summary\": \"2-3 sentence narrative...\",\n      \"key_themes\": [\"theme1\", \"theme2\", \"theme3\"],\n      \"date_range\": \"YYYY-YYYY or description\",\n      \"story_count\": {{ stories | length }}\n    }\n  \"#\n}\n",
    "main.baml": "// BAML configuration for story extraction\n\nclient<llm> GPT4o {\n  provider openai\n  options {\n    model \"gpt-4o-2024-08-06\"\n    api_key env.OPENAI_API_KEY\n    temperature 0\n  }\n}\n\nclient<llm> GPT4oMini {\n  provider openai\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n    temperature 0\n  }\n}\n\n// Auto-resolve to best available model (GPT-5)\nclient<llm> AutoModel {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n    reasoning_effort \"medium\"\n  }\n}\n\nclass DateInfo {\n  asserted_text string? @description(\"ALWAYS capture original date text verbatim from chapter, e.g., 'spring 1984', 'early 1980s', 'March 1996'\")\n  parsed string? @description(\"Parse to ISO 8601 EDTF format: '1984-03~' (approx), '1984?' (uncertain), '1984-03/1984-06' (range), '198X' (1980s), '1984-XX' (sometime in 1984)\")\n  precision string? @description(\"Auto-filled from parsed format: 'day', 'month', 'year', 'decade', 'range'\")\n}\n\nclass Location {\n  place_name string @description(\"Name of the place\")\n  lat float? @description(\"Latitude\")\n  lon float? @description(\"Longitude\")\n  place_type string? @description(\"Type of place: office, lab, factory, etc.\")\n  geo_precision string? @description(\"building, campus, city, region\")\n  visitability string? @description(\"public, private, historical\")\n  note string? @description(\"Additional context\")\n}\n\nclass Person {\n  name string @description(\"Person's name\")\n  role_at_time string? @description(\"Role at the time of the story\")\n  team string? @description(\"Team or department\")\n  affiliation string? @description(\"Company or organization\")\n}\n\nclass Product {\n  product_line string? @description(\"Product line\")\n  model string? @description(\"Model name or number\")\n  codename string? @description(\"Internal codename\")\n  generation string? @description(\"Generation or version\")\n  design_language string? @description(\"Design language or style\")\n}\n\nclass Company {\n  name string @description(\"Company name\")\n  relationship string? @description(\"Relationship to the story: beneficiary, competitor, partner, etc.\")\n}\n\nclass Provenance {\n  source_type string @description(\"Type of source: book, interview, memo, etc.\")\n  citation string? @description(\"Citation text\")\n  isbn string? @description(\"ISBN if book source\")\n  author string? @description(\"Author of source\")\n  pub_year int? @description(\"Publication year\")\n  quote_snippet string? @description(\"Direct quote from source\")\n}\n\nclass Relationships {\n  contradicts string[]? @description(\"Story IDs this contradicts\")\n  references string[]? @description(\"Story IDs this references\")\n  precedes string[]? @description(\"Story IDs this precedes\")\n}\n\nclass Media {\n  asset_type string @description(\"Type: photo, video, document, etc.\")\n  uri string? @description(\"URI to the asset\")\n  credit string? @description(\"Credit/attribution\")\n  license string? @description(\"License type\")\n  date string? @description(\"Date of asset\")\n}\n\nclass Story {\n  story_id string @description(\"Use 'auto_or_uuid' to auto-generate\")\n  title string @description(\"Short descriptive title\")\n  summary string @description(\"Compelling 200-350 char story excerpt for map pins. Front-load drama/conflict/scale. Include vivid details (quotes, numbers, sensory descriptions). Assume reader skimmed book - provide context.\")\n  dates DateInfo? @description(\"Date information\")\n  locations Location[]? @description(\"Locations mentioned in the story\")\n  forward_locale Location? @description(\"Forward-looking location where impact occurred\")\n  people Person[]? @description(\"People involved\")\n  products Product[]? @description(\"Products mentioned\")\n  companies Company[]? @description(\"Companies involved\")\n  event_type string[]? @description(\"Event types: DesignDecision, Prototype, ProductLaunch, etc.\")\n  themes string[]? @description(\"Themes: innovation, conflict, partnership, etc.\")\n  tone string[]? @description(\"Tone: triumphant, tense, nostalgic, etc.\")\n  business_phase string? @description(\"Business phase or era\")\n  era string? @description(\"Era description\")\n  relationships Relationships? @description(\"Relationships to other stories\")\n  provenance Provenance[]? @description(\"Source citations\")\n  confidence float @description(\"Confidence score 0-1\")\n  freeform_tags string[]? @description(\"Freeform tags\")\n  media Media[]? @description(\"Media assets\")\n}\n\nfunction ExtractStories(chapter_text: string, book_context: string) -> Story[] {\n  client AutoModel\n  prompt #\"\n    You are extracting structured stories from a chapter of a book about Apple Computer history.\n\n    Book context: {{ book_context }}\n\n    Chapter text:\n    ---\n    {{ chapter_text }}\n    ---\n\n    Instructions:\n    1. Extract 0 or more Story objects from this chapter\n    2. Focus on SPECIFIC, CONCRETE stories rather than general summaries:\n       - Extract stories about particular incidents, events, decisions, or actions\n       - Look for grounding details: named people, specific numbers, locations, dates, quotes\n       - A story should have narrative specificity, not just list facts or trends\n\n       ❌ Skip only:\n          - Pure background or context paragraphs without a specific event\n          - Multi-year trend summaries without concrete incidents\n          - Abstract lists of challenges or factors\n\n       ✅ Good story markers (include a good strong marker or if story has a few):\n          - Named individuals taking action or making decisions (especially main characters like Jobs, Cook, Wozniak, Sculley etc.)\n          - Specific amounts, dates, or quantities (e.g., \"50,000 units\", \"March 1984\")\n          - Identifiable places or facilities (e.g., \"Cupertino factory\", \"Bandley Drive\")\n          - Clear cause-and-effect or turning points\n          - Direct quotes or specific conflicts between people/companies\n          - Concrete products, prototypes, or technical decisions\n    3. Each story must be grounded in the chapter text - no external knowledge\n    4. Use \"auto_or_uuid\" for story_id to auto-generate\n    5. Include provenance when available\n    6. Assign confidence based on narrative detail and specificity (range: 0.5-0.8 is typical)\n    7. Extract only factual information, not speculation\n    8. For SUMMARIES - write compelling story excerpts for map pins (200-350 chars):\n       - Front-load the most dramatic/interesting element: conflict, surprise, scale, stakes\n       - Include vivid details: specific numbers, direct quotes, sensory descriptions\n       - Provide context for readers who only skimmed the book - explain significance\n       - Show what was at risk or why this moment mattered\n       - Examples of transformation:\n         * Weak: \"Apple had a trademark dispute in China\"\n         * Strong: \"Apple paid $60 million to settle after Chinese courts ruled Shenzhen-based Proview had registered 'iPad' in 2000, threatening tablet sales across China\"\n    9. For DATES - extract if present in text (don't hallucinate):\n       - IF a date/timeframe is mentioned in the chapter text:\n         * asserted_text: REQUIRED - capture the exact original phrase verbatim\n         * parsed: REQUIRED - convert to ISO 8601 EDTF format\n         * precision: REQUIRED - specify granularity\n       - Rough timeframes are better than nothing (e.g., \"early 2000s\", \"following year\")\n       - IF no date/timeframe in text: set dates to null (don't guess or infer)\n\n       EDTF format examples:\n       * \"March 15, 2013\" → asserted_text: \"March 15, 2013\", parsed: \"2013-03-15\", precision: \"day\"\n       * \"spring 1984\" → asserted_text: \"spring 1984\", parsed: \"1984-03/1984-06\", precision: \"range\"\n       * \"early 1980s\" → asserted_text: \"early 1980s\", parsed: \"1981/1985\", precision: \"range\"\n       * \"late March 1996\" → asserted_text: \"late March 1996\", parsed: \"1996-03~\", precision: \"month\"\n       * \"summer of 1997\" → asserted_text: \"summer of 1997\", parsed: \"1997-06/1997-09\", precision: \"range\"\n       * \"1984\" → asserted_text: \"1984\", parsed: \"1984\", precision: \"year\"\n       * \"1980s\" → asserted_text: \"1980s\", parsed: \"198X\", precision: \"decade\"\n       * \"around 2015\" → asserted_text: \"around 2015\", parsed: \"2015~\", precision: \"year\"\n       * \"possibly 1984\" → asserted_text: \"possibly 1984\", parsed: \"1984?\", precision: \"year\"\n    10. For LOCATIONS - capture rich contextual notes for geocoding:\n       - place_name: REQUIRED - extract the location name\n       - lat/lon: OPTIONAL - provide coordinates when possible:\n         * If text has exact coordinates → use them, set geo_precision: \"exact\"\n         * For well-known places (major cities, famous buildings, company headquarters) → provide approximate coordinates from your knowledge\n         * Set geo_precision appropriately: \"approximate-building\" (for specific buildings), \"approximate-city\" (for cities), \"approximate-region\" (for regions/states)\n         * For unknown/ambiguous places → leave lat/lon null\n       - note: Include rich contextual details from text to assist future precise geocoding:\n         * Temporal markers: \"Fremont factory (1984-1996, closed due to Mac sales collapse)\"\n         * Functional details: \"340,000 sq ft Macintosh assembly plant, 27-second cycle time\"\n         * Named entities: \"Acquired by SCI Systems for ~$200M in March 1996\"\n         * Scale/ownership: \"Apple's $20M state-of-the-art factory\"\n         * Story significance: Why this location matters to the narrative\n         * Example: \"Foxconn Longhua facility, Shenzhen (2010-present). 230k workers, iPhone assembly. Site of 2010 worker suicides.\"\n       - place_type: factory, headquarters, city, campus, office, lab, etc. (when evident)\n    11. For people, extract names and roles when mentioned\n    12. For companies, extract names and their relationship to the story\n    13. For products, extract product names and details\n    14. Extract themes, event_type, and tone when evident from the narrative\n    15. When in doubt, prefer inclusion if the story has concrete grounding details\n\n    Return a JSON array of Story objects matching the schema.\n  \"#\n}\n",
}

def get_baml_files():
    return _file_map